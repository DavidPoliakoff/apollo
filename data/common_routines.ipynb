{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                \\     _ \\   _ \\  |     |      _ \\  \n",
      "               _ \\   |   | |   | |     |     |   | \n",
      "              ___ \\  ___/  |   | |     |     |   | \n",
      "            _/    _\\_|    \\___/ _____|_____|\\___/  \n",
      "                                                   \n",
      "           -  -  -  --  --  ---  --= --== ==*# ###>\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This \"preamble\" code gets executed automatically when the main Notebook is run:\n",
    "#\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn as skl \n",
    "from sklearn                 import metrics\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.tree            import DecisionTreeRegressor\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm             import SVC \n",
    "\n",
    "\n",
    "#import ipywidgets as widgets\n",
    "#from IPython.display import display, HTML\n",
    "\n",
    "#\n",
    "# NOTE: Commented out until ipywidgets works on Quartz\n",
    "#\n",
    "# Set up the UI:\n",
    "#trace_progress = widgets.IntProgress(\n",
    "#    value=0, min=0, max=10, step=1,\n",
    "#    description='Processing:', orientation='horizontal',\n",
    "#    bar_style='') # 'success', 'info', 'warning', 'danger' or ''\n",
    "#trace_summary = widgets.Output()\n",
    "#trace_detail  = widgets.Output()\n",
    "#trace_accordion = widgets.Accordion(children=[trace_summary, trace_detail])\n",
    "#trace_accordion.set_title(0, 'Summary')\n",
    "#trace_accordion.set_title(1, 'Detail')\n",
    "#trace_box = widgets.Box(children=[trace_progress, trace_accordion])\n",
    "#\n",
    "#plot_progress = widgets.IntProgress(\n",
    "#    value=0, min=0, max=10, step=1,\n",
    "#    description='Processing:', orientation='horizontal',\n",
    "#    bar_style='') # 'success', 'info', 'warning', 'danger' or ''\n",
    "#plot_summary = widgets.Output()\n",
    "#plot_detail  = widgets.Output()\n",
    "#plot_accordion = widgets.Accordion(children=[plot_summary, plot_detail])\n",
    "#plot_accordion.set_title(0, 'Summary')\n",
    "#plot_accordion.set_title(1, 'Detail')\n",
    "#plot_box = widgets.Box(children=[plot_progress, plot_accordion])\n",
    "#\n",
    "#tab_nest = widgets.Tab(children=[trace_box, plot_box])\n",
    "#tab_nest.set_title(0, 'Trace')\n",
    "#tab_nest.set_title(1, 'Plot')\n",
    "#tab_nest.selectedIndex = None\n",
    "#\n",
    "#display(tabNest)\n",
    "\n",
    "#trace_thread = threading.Thread(\n",
    "#    target=project_model_over_trace,\n",
    "#    args=(data, trace_progress, trace_summary, trace_detail))\n",
    "\n",
    "#plot_thread = threading.Thread(\n",
    "#    target=plot_apollo_vs_normal,\n",
    "#    args=(data))\n",
    "\n",
    "#trace_thread.start()\n",
    "#plot_thread.start()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "                \\     _ \\   _ \\  |     |      _ \\  \n",
    "               _ \\   |   | |   | |     |     |   | \n",
    "              ___ \\  ___/  |   | |     |     |   | \n",
    "            _/    _\\_|    \\___/ _____|_____|\\___/  \n",
    "                                                   \n",
    "           -  -  -  --  --  ---  --= --== ==*# ###>\n",
    "      \"\"\")\n",
    "\n",
    "def tree_to_data(decision_tree, feature_names=None, name_swap=None, y=None):\n",
    "    def node_to_data(tree, node_id, criterion):\n",
    "        if not isinstance(criterion, skl.tree.tree.six.string_types):\n",
    "            criterion = \"impurity\"\n",
    "\n",
    "        value = tree.value[node_id]\n",
    "        if tree.n_outputs == 1:\n",
    "            value = value[0, :]\n",
    "\n",
    "        if tree.children_left[node_id] == skl.tree._tree.TREE_LEAF:\n",
    "            return {\n",
    "                \"id\": node_id,\n",
    "                \"criterion\": criterion,\n",
    "                \"impurity\": tree.impurity[node_id],\n",
    "                \"samples\": tree.n_node_samples[node_id],\n",
    "                \"value\": list(value),\n",
    "                \"class\": decision_tree.classes_[np.argmax(value)]\n",
    "            }\n",
    "        else:\n",
    "            if feature_names is not None:\n",
    "                feature = feature_names[tree.feature[node_id]]\n",
    "            else:\n",
    "                feature = tree.feature[node_id]\n",
    "\n",
    "            if \"=\" in feature:\n",
    "                ruleType = \"=\"\n",
    "                ruleValue = \"false\"\n",
    "            else:\n",
    "                ruleType = \"<=\"\n",
    "                ruleValue = \"%.4f\" % tree.threshold[node_id]\n",
    "\n",
    "            return {\n",
    "                \"id\": node_id,\n",
    "                \"rule\": \"%s %s %s\" % (feature, ruleType, ruleValue),\n",
    "                criterion: tree.impurity[node_id],\n",
    "                \"samples\": tree.n_node_samples[node_id],\n",
    "            }\n",
    "\n",
    "    def recurse(tree, node_id, criterion, parent=None, depth=0):\n",
    "        left_child = tree.children_left[node_id]\n",
    "        right_child = tree.children_right[node_id]\n",
    "\n",
    "        node = node_to_data(tree, node_id, criterion)\n",
    "\n",
    "        if left_child != skl.tree._tree.TREE_LEAF:\n",
    "            node[\"left\"] = recurse(tree,\n",
    "                                   left_child,\n",
    "                                   criterion=criterion,\n",
    "                                   parent=node_id,\n",
    "                                   depth=depth + 1)\n",
    "            node[\"right\"] = recurse(tree,\n",
    "                                    right_child,\n",
    "                                    criterion=criterion,\n",
    "                                    parent=node_id,\n",
    "                                    depth=depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    if isinstance(decision_tree, skl.tree.tree.Tree):\n",
    "        return recurse(decision_tree, 0, criterion=\"impurity\")\n",
    "    else:\n",
    "        return recurse(decision_tree.tree_, 0, criterion=decision_tree.criterion)\n",
    "\n",
    "def tree_to_simple_str(decision_tree, feature_names=None, name_swap=None, y=None):\n",
    "    def node_to_data(tree, node_id, criterion):\n",
    "        if not isinstance(criterion, skl.tree.tree.six.string_types):\n",
    "            criterion = \"impurity\"\n",
    "\n",
    "        value = tree.value[node_id]\n",
    "        if tree.n_outputs == 1:\n",
    "            value = value[0, :]\n",
    "\n",
    "        if tree.children_left[node_id] == skl.tree._tree.TREE_LEAF:\n",
    "            return {\n",
    "                \"class\": decision_tree.classes_[np.argmax(value)]\n",
    "            }\n",
    "        else:\n",
    "            if feature_names is not None:\n",
    "                feature = feature_names[tree.feature[node_id]]\n",
    "            else:\n",
    "                feature = tree.feature[node_id]\n",
    "\n",
    "            if \"=\" in feature:\n",
    "                ruleType = \"=\"\n",
    "                ruleValue = \"false\"\n",
    "            else:\n",
    "                ruleType = \"<=\"\n",
    "                ruleValue = \"%.4f\" % tree.threshold[node_id]\n",
    "\n",
    "            return {\n",
    "                \"rule\": \"%s %s %s\" % (feature, ruleType, ruleValue),            \n",
    "            }\n",
    "\n",
    "    def recurse(tree, node_id, criterion, parent=None, depth=0):\n",
    "        left_child = tree.children_left[node_id]\n",
    "        right_child = tree.children_right[node_id]\n",
    "\n",
    "        node = node_to_data(tree, node_id, criterion)\n",
    "\n",
    "        if left_child != skl.tree._tree.TREE_LEAF:\n",
    "            node[\"left\"] = recurse(tree,\n",
    "                                   left_child,\n",
    "                                   criterion=criterion,\n",
    "                                   parent=node_id,\n",
    "                                   depth=depth + 1)\n",
    "            node[\"right\"] = recurse(tree,\n",
    "                                    right_child,\n",
    "                                    criterion=criterion,\n",
    "                                    parent=node_id,\n",
    "                                    depth=depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    if isinstance(decision_tree, skl.tree.tree.Tree):\n",
    "        return recurse(decision_tree, 0, criterion=\"impurity\")\n",
    "    else:\n",
    "        return recurse(decision_tree.tree_, 0, criterion=decision_tree.criterion)\n",
    "\n",
    "\n",
    "def construct_model_from_flush(data, flush_key):\n",
    "    # Grab the table\n",
    "    td = data[flush_key]\n",
    "    \n",
    "    # Make the data like the query for online learning\n",
    "    # TODO\n",
    "    \n",
    "    # Filter the refined data\n",
    "    td['region_name'] = pd.Categorical(td['region_name'])\n",
    "    td['region_name_id'] = td['region_name'].cat.codes\n",
    "    #\n",
    "    name_swap = td[['region_name', 'region_name_id']]\\\n",
    "            .groupby(['region_name', 'region_name_id'], as_index=False, sort=True)\\\n",
    "            .first()\n",
    "\n",
    "    grp_td = td.groupby(by=['region_name', 'region_name_id', 'num_elements', 'policy_index'],\n",
    "                            as_index=False).agg({\n",
    "                                'time_avg':'min'\n",
    "                            })\n",
    "\n",
    "    region_names = td['region_name'].unique().tolist()\n",
    "    unique_policies = grp_td['policy_index'].unique().tolist()\n",
    "    \n",
    "    print(\"    td.shape = %s\" % str(td.shape))\n",
    "    print(\"grp_td.shape = %s\" % str(grp_td.shape))\n",
    "    print(\"len(region_names) = %s\" % len(region_names))\n",
    "    print(\"\\nunique_policies = %s\\n\" % str(unique_policies))\n",
    "    \n",
    "    #print(grp_td.to_string())\n",
    "    \n",
    "    drop_fields = ['region_name', 'region_name_id', 'policy_index', 'time_avg']\n",
    "\n",
    "    feature_names = [f for f in grp_td.columns if f not in drop_fields]\n",
    "    model_count = 0\n",
    "    \n",
    "    # Set up the SKL pipeline\n",
    "    # Build a model for each region\n",
    "    all_skl_models = {}\n",
    "    all_types_rule = {}\n",
    "    all_rules_json = {}\n",
    "    all_least_json = {}\n",
    "    all_timed_json = {}\n",
    "    all_sizes_data = {}\n",
    "\n",
    "    one_big_tree = False\n",
    "\n",
    "    print(\"Training...\")\n",
    "    for region in region_names:\n",
    "        model_count += 1\n",
    "    \n",
    "        if one_big_tree:\n",
    "            rd = grp_td\n",
    "            region = \"__ANY_REGION__\"\n",
    "        else:\n",
    "            rd = grp_td[grp_td['region_name'] == region]\n",
    "\n",
    "        if (rd.shape[0] < 1): \n",
    "            continue\n",
    "\n",
    "        y = rd['policy_index'].astype(int)\n",
    "        x = rd.drop(drop_fields, axis=\"columns\").values.astype(float)\n",
    "        \n",
    "        #example = DecisionTreeClassifier(\n",
    "        #         class_weight=None, criterion='gini', max_depth=6,\n",
    "        #         max_features=x.shape[1], max_leaf_nodes=None,\n",
    "        #         min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "        #         min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "        #         presort=False, random_state=None, splitter='best'))]\n",
    "\n",
    "        clf = DecisionTreeClassifier(\n",
    "                 class_weight=None, criterion='gini', max_depth=2,\n",
    "                 min_samples_leaf=1, min_samples_split=2)\n",
    "\n",
    "        # Conduct some model evaluation:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1) # 75% training and 25% test\n",
    "\n",
    "        pipe = [('estimator', clf)]\n",
    "        model = Pipeline(pipe)\n",
    "\n",
    "        model.fit(x, y)\n",
    "\n",
    "        trained_model = model.named_steps['estimator']\n",
    "        y_pred = trained_model.predict(x_test)\n",
    "\n",
    "        # Does not work for small splits:\n",
    "        #scores = cross_val_score(model, x, y, cv=5)\n",
    "\n",
    "        all_types_rule[region] = \"DecisionTree\"\n",
    "        all_rules_json[region] = tree_to_data(trained_model, feature_names, name_swap, y)\n",
    "        all_least_json[region] = -1\n",
    "        all_timed_json[region] = True\n",
    "        all_sizes_data[region] = str(x.shape)\n",
    "        all_skl_models[region] = trained_model\n",
    "        \n",
    "        #print(\"model[\\\"\" + str(region) + \"\\\"].x_shape\" + \"%-12s\" % str(x.shape) \\\n",
    "        #        + \".y_shape\" + \"%-12s\" % str(y.shape) \\\n",
    "        #        + \"%22s\" % (\"Acc%: \" + \"%6s\" % (\"%3.2f\" % (100.0 * metrics.accuracy_score(y_test, y_pred)))))\n",
    "\n",
    "        if one_big_tree:\n",
    "            #print(\"\")\n",
    "            #print(tree_to_simple_str(trained_model, feature_names, name_swap, y))\n",
    "            #print(\"\")\n",
    "            break\n",
    "\n",
    "    #\n",
    "    # Now we're done building models.\n",
    "    #\n",
    "    if one_big_tree == False:\n",
    "        model_def = {\n",
    "                \"guid\": 0,\n",
    "                \"driver\": {\n",
    "                    \"rules\": all_rules_json,\n",
    "                    \"least\": all_least_json,\n",
    "                    \"timed\": all_timed_json,\n",
    "                    },\n",
    "                \"region_names\": list(region_names),\n",
    "                \"region_sizes\": all_sizes_data,\n",
    "                \"region_types\": all_types_rule,\n",
    "                \"features\": {\n",
    "                    \"count\": len(feature_names),\n",
    "                    \"names\": feature_names,\n",
    "                    },\n",
    "                }\n",
    "    else:\n",
    "        model_def = {\n",
    "                \"guid\": 0,\n",
    "                \"driver\": {\n",
    "                    \"rules\": all_rules_json,\n",
    "                    \"least\": all_least_json,\n",
    "                    \"timed\": all_timed_json,\n",
    "                    },\n",
    "                \"region_names\": \"__ANY_REGION__\",\n",
    "                \"region_sizes\": all_sizes_data,\n",
    "                \"region_types\": all_types_rule,\n",
    "                \"features\": {\n",
    "                    \"count\": len(feature_names),\n",
    "                    \"names\": feature_names,\n",
    "                    },\n",
    "                }\n",
    "\n",
    "    # Add in a default model (Static, OMP defaults) for any unnamed region:\n",
    "    if one_big_tree == False:\n",
    "        model_def[\"region_names\"].append(\"__ANY_REGION__\")\n",
    "        model_def[\"region_sizes\"][\"__ANY_REGION__\"] = \"(0, 0)\"\n",
    "        model_def[\"region_types\"][\"__ANY_REGION__\"] = \"Static\"\n",
    "        model_def[\"driver\"][\"rules\"][\"__ANY_REGION__\"] = \"0\"\n",
    "        model_def[\"driver\"][\"least\"][\"__ANY_REGION__\"] = \"-1\"\n",
    "        model_def[\"driver\"][\"timed\"][\"__ANY_REGION__\"] = True\n",
    "\n",
    "    #model_as_json = json.dumps(model_def, sort_keys=False, indent=4, ensure_ascii=True) + \"\\n\"\n",
    "    \n",
    "    return all_skl_models\n",
    "\n",
    "\n",
    "def hide_traceback(exc_tuple=None, filename=None, tb_offset=None,\n",
    "                   exception_only=False, running_compiled_code=False):\n",
    "    import sys\n",
    "    ipython = get_ipython()\n",
    "    etype, value, tb = sys.exc_info()\n",
    "    return ipython._showtraceback(etype, value, ipython.InteractiveTB.get_exception_only(etype, value))\n",
    "\n",
    "def format_bytes(size):\n",
    "    # 2**10 = 1024\n",
    "    power = 2**10\n",
    "    n = 0\n",
    "    power_labels = {0 : '', 1: 'k', 2: 'M', 3: 'G', 4: 'T'}\n",
    "    while size > power:\n",
    "        size /= power\n",
    "        n += 1\n",
    "    return str(\"%3.3f \" % size + power_labels[n] + 'B')\n",
    "\n",
    "def load_csv_data(data):\n",
    "    def load_and_report(data, dfkey, csvfile):\n",
    "        data[dfkey] = pd.read_csv(data['path'] + '/' + csvfile)\n",
    "        dfbytes = data[dfkey].memory_usage(index=False, deep=True).sum()\n",
    "        print(\"       data[%s]   %10s   %s\" % (dfkey, format_bytes(dfbytes), csvfile))\n",
    "        return data\n",
    "    ###\n",
    "    print(\"Data source:\\n\\t%s\\n\" % data['path'])\n",
    "    print(\"Loading:\")\n",
    "    data = load_and_report(data, 'apollo.trace', data['apollo.tracefile'])\n",
    "    data = load_and_report(data, 'apollo.flush', data['apollo.flushfile'])\n",
    "    data = load_and_report(data, 'apollo.steps', data['apollo.stepsfile'])\n",
    "    data = load_and_report(data, 'normal.steps', data['normal.stepsfile'])\n",
    "    print(\"\")\n",
    "    return data\n",
    "\n",
    "#\n",
    "# To suppress traceback output on errors, add this to main:\n",
    "#\n",
    "#ipython = get_ipython()\n",
    "#ipython.showtraceback = hide_traceback\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
