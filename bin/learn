#!/usr/bin/env python
import sys

from rlsl.util.loader import PandasCaliperLoader, PandasInstructionLoader
from rlsl.util.transformers import *
from rlsl.util.codegen import CodeGenerator
from rlsl.util import df_to_unique_csv
from rlsl.util.timer import Timer

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import *

from sklearn.cross_validation import cross_val_score

from sklearn.pipeline import Pipeline

import numpy as np
import pandas as pd

def get_train_test_inds(y,train_proportion=0.7):
    '''Generates indices, making random stratified split into training set and testing sets
    with proportions train_proportion and (1-train_proportion) of initial sample.
    y is any iterable indicating classes of each observation in the sample.
    Initial proportions of classes inside training and
    testing sets are preserved (stratified sampling).
    '''

    y=np.array(y)
    train_inds = np.zeros(len(y),dtype=bool)
    test_inds = np.zeros(len(y),dtype=bool)
    values = np.unique(y)
    for value in values:
        value_inds = np.nonzero(y==value)[0]
        np.random.shuffle(value_inds)
        n = int(train_proportion*len(value_inds))

        train_inds[value_inds[:n]]=True
        test_inds[value_inds[n:]]=True

    return train_inds,test_inds


def optimal_times(data):
    print "Optimal times."
    print data.groupby('problem_size')['time.duration'].sum()


def get_code(X, y, labelencoder):
    adf = AutoDataFrameMapper()
    pipeline = Pipeline([
        ('mapper', adf),
        ('clf', DecisionTreeClassifier(max_leaf_nodes=15))])
    features = adf.get_feature_list(X)
    pipeline.fit(X,y)
    CodeGenerator().get_code(pipeline.steps[-1][1], features,
                             labelencoder.get_labels())


CLASSIFIERS = [
    'DecisionTreeClassifier',
]

clfs = []

for c in CLASSIFIERS:
    clfs.append(globals()[c]())

data = {}
timers = {}
config = {}
config['app'] = 'lulesh'

with Timer() as t:
    data['loop'] = PandasCaliperLoader('%s' % (sys.argv[1]), id_column='loop_count').get_data()
    data['instruction'] = PandasInstructionLoader('%s' % sys.argv[2]).get_data().fillna(0)
timers['load'] = t.msecs

with Timer() as t:
    data['loop'] = DropThreads().transform(data['loop'])
    #data['loop'] = SelectThreads().transform(data['loop'])
    data['all_loop'] = data['loop']
    data['loop'] = FilterDuplicates().transform(data['loop'])
timers['transform'] = t.msecs

with Timer() as t:
    data['all'] = pd.merge(data['loop'], data['instruction'], left_on='loop_id', right_on='loop', how='left')
    data['all'].drop('loop', axis=1, inplace=True)
    #data['all'] = data['loop']
timers['merge'] = t.msecs

from IPython import embed; embed()

X = data['all']
X = X.iloc[np.random.permutation(len(X))]

DROPPED_FEATURES = ['loop_id', 'callpath.address', 'num_threads', 'time.duration', 'seg_exec', 'seg_it', 'loop_count', 'reduction']

#FONE = [x for x in list(X) if x not in ['num_indices']]
#FTWO = [x for x in list(X) if x not in ['num_indices', 'problem_size']]
#FTHREE = [x for x in list(X) if x not in ['num_indices', 'problem_size', 'timestep']]
#FFOUR = [x for x in list(X) if x not in ['num_indices', 'problem_size', 'timestep', '8b48']]
#FFIVE = [x for x in list(X) if x not in ['num_indices', 'problem_size', 'timestep', '8b48', '2674']]

FONE = [x for x in list(X) if x not in ['num_indices']]
FTWO = [x for x in list(X) if x not in ['num_indices', 'problem_size']]
FTHREE = [x for x in list(X) if x not in ['num_indices', 'problem_size', 'timestep']]
FFOUR = [x for x in list(X) if x not in ['num_indices', 'problem_size', 'timestep', '58808d48']]
FFIVE = [x for x in list(X) if x not in ['num_indices', 'problem_size', 'timestep', '58808d48', '55']]

FTEN = [x for x in list(X) if x not in [ 'num_indices', 'problem_size', 'timestep', '8b48', '2674', '58808d48', '68808d48', 'ff47eee8', 'b87589']]

#fsets = [FONE, FTWO, FTHREE, FFOUR, FFIVE]
fsets = [DROPPED_FEATURES]
#fsets = [FTEN]

labelencoder = GetLabels()
#labelencoder = GetThreads()
y = labelencoder.transform(X)

data['full'] = X

for fset in fsets:
    X = FeatureDropper().transform(data['full'], columns=fset)

    #get_code(X, y, labelencoder)

    embed()

    for i,c  in enumerate(CLASSIFIERS):
        pipeline = Pipeline([
            ('mapper', AutoDataFrameMapper()),
            ('clf', clfs[i])])

        scores = cross_val_score(pipeline, X, y, cv=3)
        print "%0.6f, %s" % (scores.mean(), config['app'])

        sys.exit()

        print "Actual time."
        train_inds, test_inds = get_train_test_inds(y)

        pipeline.fit(X[train_inds], y[train_inds])
        results = pipeline.predict(X)
        resultlabels = labelencoder.get_encoder().inverse_transform(results)

        test_df = data['full'][['problem_size', 'loop_count', 'seg_it', 'seg_exec']]
        #test_df['num_threads'] = resultlabels

        #merged_test_df = pd.merge(test_df, data['all_loop'][['loop_count', 'problem_size',
        #                                                 'num_threads',
        #                                                 'seg_it', 'seg_exec',
        #                                                 'time.duration']],
        #                         on=['problem_size', 'loop_count', 'seg_it', 'seg_exec'], how='inner')

        #mdf = merged_test_df[(merged_test_df['num_threads_x'] == merged_test_df['num_threads_y'])]

        test_df['seg_it'] = map(lambda x: x.split(' ')[0],
                                labelencoder.get_encoder().inverse_transform(results))
        test_df['seg_exec'] = map(lambda x: x.split(' ')[1],
                                labelencoder.get_encoder().inverse_transform(results))

        merged_test_df = pd.merge(test_df, data['all_loop'][['loop_count', 'problem_size', 'seg_it', 'seg_exec', 'time.duration']], on=['problem_size', 'loop_count'], how='inner')
        mdf = merged_test_df[(merged_test_df['seg_exec_x'] == merged_test_df['seg_exec_y']) & (merged_test_df['seg_it_x'] == merged_test_df['seg_it_y'])]

        print mdf.groupby('problem_size')['time.duration'].sum()

        pipeline = Pipeline([
            ('mapper', AutoDataFrameMapper()),
            ('clf', RandomForestClassifier())])

        with Timer() as t:
            pipeline.fit(X,y)
        features = AutoDataFrameMapper().get_feature_list(X)
        forest = pipeline.steps[-1][1]
        importances = forest.feature_importances_
        std = np.std([tree.feature_importances_ for tree in forest.estimators_],
                    axis=0)
        indices = np.argsort(importances)[::-1]

        print("Feature ranking:")
        for f in range(min(10, len(features))):
            print("%d. feature %s (%f)" % (f + 1, features[indices[f]], importances[indices[f]]))
