#!/usr/bin/env python

import re
import sys
import itertools
import argparse

from sciload import *

from sklearn.cross_validation import cross_val_score, train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.feature_extraction import DictVectorizer
from sklearn.tree import export_graphviz, DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.utils import shuffle


def get_cross_validation_scores(clf, X, y, n):
    return cross_val_score(clf, X, y, cv=n) 


def get_feature_importances(clf):
    importances = clf.feature_importances_
    #std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)
    return importances, np.argsort(importances)[::-1]


def dump_graphviz(clf, features, filename):
    with open(filename, 'w') as f:
        f = export_graphviz(clf, feature_names=features.get_feature_names(), out_file=f)


if __name__ == '__main__':

    parser = argparse.ArgumentParser(description="Analyse RAJA data.")
    parser.add_argument('-a', '--application', help='Is this LULESH or ARES data?', type=str)
    parser.add_argument('-c', '--classifier', help='Which machine learning algorithm to use [tree,forest]?', type=str)
    parser.add_argument('-f', '--feature', help='How should loops be interpreted in ARES [package, file]?', type=str)
    parser.add_argument('-p', '--predict', help='What should be predicted [policy, runtime]?', type=str)
    parser.add_argument('-v', '--verbose', action='store_true', help='Print feature combinations, rather than just feature set sizes')
    parser.add_argument('-i', '--importances', action='store_true', help='Print importance data for each feature')
    parser.add_argument('data', help='CSV file containing RAJA data.')

    args = parser.parse_args(sys.argv[1:])

    if args.application.lower() == 'ares':
        dtype={'names': ('problem size', 'outer', 'inner', 'loop type', 'set type', 'loop', 'range size', 'segments', 'function size', 'time'),
            'formats': ('i4', 'S64', 'S64', 'S64', 'S64', 'S1024', 'i4', 'i4', 'i4', np.float64)}
        #xtype={'names': ('problem size', 'loop type', 'set type', 'loop', 'range size', 'segments', 'function size', 'best'),
        #        'formats': ('i4', 'S64', 'S64', 'S1024', 'i4', 'i4', 'i4', 'bool')}
        #xtype={'names': ('problem size', 'loop type', 'set type', 'loop', 'range size', 'segments', 'function size', 'best'),
        #        'formats': ('i4', 'S64', 'S64', 'S1024', 'i4', 'i4', 'i4', 'bool')}
        xtype={'names': ('problem size', 'loop type', 'set type', 'range size', 'segments', 'function size', 'best'),
                'formats': ('i4', 'S64', 'S64', 'i4', 'i4', 'i4', 'bool')}

        ytype={'names': ('outer', 'inner'),
            'formats': ('S64', 'S64')}
    elif args.application.lower() == 'lulesh':
        dtype = None
        xtype={'names': ('loop type', 'set type', 'range size', 'segments', 'best'),
                'formats': ('S64', 'S64', 'i4', 'i4', 'bool')}
        ytype = None

    data = loadcsvdata(args.data, dtype)

    X = get_x(data, xtype)
    y = get_y(data, ytype)

    if not args.predict:
        args.predict = 'policy'

    if args.predict.lower() == 'policy':
        y = y[['inner', 'outer']]
    else:
        y = y[['time']]

    print args

    #X, y = shuffle(X,y)

    def extract_package(s):
        match = re.search(r'sources/([^/]*)/', s)
        if match:
            return match.group(1)
        else:
            return 'Unknown'

    def extract_file(s):
        match = re.search(r'/([^/]+)\.cc', s)
        if match:
            return match.group(1)
        else:
            return 'Unknown'

    names = X.dtype.names
    
#    if args.application.lower() == 'ares':
#        if args.feature:
#            if args.feature.lower() == 'package':
#                X['loop'] = [extract_package(x) for x in X['loop']]
#            elif args.feature.lower() == 'file':
#                X['loop'] = [extract_file(x) for x in X['loop']]
#        else:
#            X['loop'] = [x.split('/')[-1] for x in X['loop']]
#
#
#    if args.application.lower() == 'lulesh' and args.importances:
#        X['loop'] = [x.split('/')[-1] for x in X['loop']]

    feature_vect = DictVectorizer(sparse=False)
    X_dict = [dict(zip(list(X.dtype.names), list(f))) for f in X]
    feature_vect.fit_transform(X_dict)

    if args.importances:
        all_feature_names = [x for x in feature_vect.get_feature_names()]
        all_feature_names_formatted = [x.replace(" ", "_") for x in feature_vect.get_feature_names()]
        print "%s %s" % ("score", " ".join(all_feature_names_formatted))
    else:
        print "Features, Accuracy"
    for l in range(0, len(names)+1):
        for subset in itertools.combinations(names, l):
            if len(subset) > 0:
                X_sub = X[list(subset)]

                X_sub = [dict(zip(list(X_sub.dtype.names), list(f))) for f in X_sub]
                #y = [dict(zip(list(y.dtype.names), l)) for l in y]

                feature_vect = DictVectorizer(sparse=False)
                #label_vect = DictVectorizer(sparse=False)

                X_sub = feature_vect.fit_transform(X_sub)
                #y = label_vect.fit_transform(y)

                X_train, X_test, y_train, y_test = train_test_split(X_sub, y, test_size = 0.4)

                folds = 10

                if args.predict.lower() == 'policy':
                    if args.classifier.lower() == 'tree':
                        clf = DecisionTreeClassifier()
                    elif args.classifier.lower() == 'forest':
                        clf = RandomForestClassifier()

                    scores = get_cross_validation_scores(clf, X_sub, y, folds)
                    if args.verbose:
                        if args.importances:
                            clf.fit(X_train,y_train)
                            importances = clf.feature_importances_
                            feature_names = [feature_vect.get_feature_names()[x] for x in range(len(importances))]
                            output_importance_string = str(scores.mean()) + " "
                            for name in all_feature_names:
                                if name in feature_names:
                                    output_importance_string += "%0.4f " % importances[feature_names.index(name)]
                                else:
                                    output_importance_string += "%0.4f " % 0.0
                            print output_importance_string
                        else:
                            print "%s , %0.8f (+/- %0.8f)" % (str(subset), scores.mean(), scores.std() / 2)
                    else:
                        print "%d, %0.8f" % (len(subset), scores.mean())
                else:
                    if args.classifier.lower() == 'tree':
                        clf = DecisionTreeRegressor()
                    elif args.classifier.lower() == 'forest':
                        clf = RandomForestRegressor()
                    
                    clf.fit(X_train, y_train)
                    # Predict
                    y_1 = clf.predict(X_test)
                    X_test_i = [np.where(X_sub==x)[0] for x in X_test]
                    print X_test_i

                    # Plot the results
                    import matplotlib
                    matplotlib.use('Agg')
                    import matplotlib.pyplot as plt

                    plt.figure()
                    X_i = np.arange(0,len(X_sub))
                    plt.scatter(X_i, y['time'], c="k", label="data")
                    plt.scatter(X_test_i, y_1, c="r", label="prediction")
                    plt.xlabel("data")
                    plt.ylabel("target")
                    plt.title("Decision Tree Regression")
                    plt.legend()
                    plt.savefig('regression.pdf',bbox_inches='tight')

                    sys.exit(0)
