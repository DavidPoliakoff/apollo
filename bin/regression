#!/usr/bin/env python
import sys

import itertools

import numpy as np
import pandas as pd

from rlsl.learn import get_kfold_score, get_kfold_pem_score
from rlsl.util import df_to_unique_csv
from rlsl.util.dtypes import LULESH_DTYPE, PATH_DTYPE
from rlsl.util.sciload import PandasFeatureLoader, PandasInstructionLoader
from rlsl.util.timer import Timer
from rlsl.metrics.performance import PerformanceErrorMetric, RuntimeScorer

from sklearn.feature_extraction import DictVectorizer
from sklearn.preprocessing import LabelBinarizer, StandardScaler
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import make_scorer
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.cross_validation import train_test_split
from sklearn.utils import shuffle

CLASSIFIERS = [
    'DecisionTreeRegressor',
    'RandomForestRegressor',
    'KNeighborsRegressor',
    ]

clfs = []

NAMES = PATH_DTYPE['names']

INPUT = {
        'deck': 'ares-jet',
        'instructions': 'ares'
        }

data = PandasFeatureLoader('/Users/david/PhD/Research/Papers/SC 2015 Machine Learning/data/learning/with-path/%s-data.csv' % INPUT['deck'], NAMES)
instruction_data = PandasInstructionLoader('/Users/david/PhD/Research/Papers/SC 2015 Machine Learning/data/learning/%s-instructions.csv' % INPUT['instructions'])

all_data = pd.merge(data.get_data(), instruction_data.get_data().fillna(0), on='loop')

df = all_data

for c in CLASSIFIERS:
    clfs.append(globals()[c]())

feature_names = [x for x in list(df) if x not in ['time', 'outer_best', 'inner_best', 'time_best', 'path', 'loop']]

y = df['time'].as_matrix()

x_num = df[[x for x in feature_names if x not in ['loop type', 'set type', 'outer', 'inner']]].as_matrix()

#scaler = StandardScaler()
#x_num = scaler.fit_transform(x_num)

x_cat = df[[x for x in ['loop type', 'set type'] if x in feature_names]].T.to_dict().values()
vectorizer = DictVectorizer(sparse=False)
vec_x_cat = vectorizer.fit_transform(x_cat)

x_inner = df['inner'].as_matrix()
binarizer = LabelBinarizer()
bin_x_inner = binarizer.fit_transform(x_inner)

x_outer = df['outer'].as_matrix()
binarizer = LabelBinarizer()
bin_x_outer = binarizer.fit_transform(x_outer)

X = np.hstack((x_num, vec_x_cat, bin_x_inner, bin_x_outer))

print "MAE...",
mea = [get_kfold_score(clf, X, y, 10, scoring='mean_absolute_error') for clf in clfs]
print "done."
print "MSE...",
mse = [get_kfold_score(clf, X, y, 10, scoring='mean_squared_error') for clf in clfs]
print "done."
print "R^2...",
rsq = [get_kfold_score(clf, X, y, 10, scoring='r2') for clf in clfs]
print "done."

mse = map(abs, mse)
mea = map(abs, mea)
print mea
print mse
print rsq

scores = []
for e,a,r,label in zip(mse, mea, rsq, CLASSIFIERS):
    score_map = {'problem size': 'all',
            'classifier':label,
            'mean_squared_error':e,
            'mean_absolute_error':a,
            'r2':r
            }

    scores.append(score_map)

scores_df = pd.DataFrame(scores)
df_to_unique_csv(scores_df, "%s-regression" % INPUT['deck'])

#
# #importances = []
# #ilist = []
# #
# #for clf,label in zip(clfs,CLASSIFIERS):
# #    clf.fit(X, y)
# #    importances = clf.feature_importances_
# #    indices = np.argsort(importances)[::-1]
# #
# #    print("Feature ranking:")
# #    for f in range(len(importances)):
# #        imap = {'rank': f+1,
# #                'feature_name': feature_names[indices[f]],
# #                'importance':importances[indices[f]],
# #                'classifier':label}
# #
# #        print("%d. %s (%f)" % (f + 1, feature_names[indices[f]], importances[indices[f]]))
# #        ilist.append(imap)
# #
# #idf = pd.DataFrame(ilist)
# #idf.to_csv('%s-importances.csv' % APP)
